#!/usr/bin/mawk -f

BEGIN{ 
OFS="\t" 
help=" \
    This script takes a grouping file and a decompressed VCF as input.\n \
    It outputs pi within each group and dxy between each pair of groups.\n \
    \n \
    Usage: \n \
    zcat file.vcf.gz | piawka [OPTIONS] groups_file - \n \
    \n \
    Options: \n \
    PIXY=1       calculate pixy-like pi instead of average weighted pi (default)\n \
    DXY=1        count between-group Dxy in addition to within-group pi (default)\n \
    MULT=1       use multiallelic sites\n \
    PERSITE=1    output values for each site instead of summary values\n \
    LOCUS='text' custom name of region to be shown in first column\n \
    HET=1        output heterozygosity, i.e. within-sample pi (unsets default DXY=1)\n \
    FST=XXX or 1 output Fst using one of the following estimators (sets DXY=1):\n \
                 HUD (default) : Hudson (1992) after Bhatia et al. (2013, eq. 10)\n \
                 WC : Weir and Cockerham (1984), biased for unequal groups with dissimilar Fst \n \
    MIS=0.5      maximum share of missing genotypes in groups at site with PIXY=0 \n \
                 default 0.5 if PIXY=0 or 1 otherwise\n \
    VERBOSE=1    output numerator and denominator as 8th and 9th column\n \
                 with PIXY=0 and PERSITE=0, numerator = sum of values and denominator = nUsed\n \
    TAJLIKE=1    output Tajima's D-like statistic (different variance; unset by PERSITE=1 or MULT=1)\n \
    \n \
    Example groups.tsv:\n \
    \n \
    sample1 grp1\n \
    sample2 grp1\n \
    sample3 grp2\n \
    sample4 grp3\n \
    \n \
    Samples missing from the VCF or groups file will be silently skipped.\n \
    If one sample is assigned to two groups, only one will be used.\n \
    \n \
    Output is the long-format table with seven columns (no header):\n \
    \n \
    locus_name, nSites, pop1, pop2, nUsed, metric, value\n \
    \n \
    where nSites = SNPs + invariant sites,\n \
          nUsed = nSites - sites with too many alleles or too much missing data\n \
    \n \
    Version: 0.7.7"
if ( !ARGV[1] ) { print help; exit }
}

# First file: store lists of group members in `groups` array
NR==FNR { 
  if ( !HET ) {
    groupmem[$1]=$2
  } else {
    groupmem[$1]=$1
  }
}

# Store first position for LOCUS name if it is not set
FIRSTDATALINE && LOCUS=="" { chrom=$1; minpos=$2; FIRSTDATALINE=0 }

# Second file (VCF), header line
NR>FNR && /^#CHROM/ {

  # Set default variable values
  if ( PIXY == "" ) { PIXY=1 }
  if ( !HET && DXY == "" ) { DXY=1 }
  if ( FST ) { DXY=1; if ( FST==1 ) { FST = "HUD" } }
  if ( TAJLIKE && MIS=="" ) { MIS=0 }
  if ( MIS == "" ) { PIXY ? MIS=1 : MIS=0.5 }
  if ( PERSITE || MULT ) { TAJLIKE=0 }

  if ( LOCUS=="" ) { FIRSTDATALINE=1 }

  # Assign sample positions to groups
  for (i=10; i<=NF; i++) {
    if ( groupmem[$i] != "" ) { 
       groupindex[i]=groupmem[$i]
       groups[groupmem[$i]]++
     }
  }
  # Store group combinations
  if ( DXY && !PERSITE ) {
    for (g in groups) {
      for (g2 in groups) {
        if (g2 < g) { combs[g,g2]++ }
      }
    }
  }
}

# Second file: process sites
NR>FNR && /^[^#]/ {

  # Inferring range for locus name
  # This counter is slower yet POSIX-compliant
  #if ( LOCUS == "" ) {
  #  if ( !minpos ) { chrom=$1; minpos=$2 }
  #  if ( $2 > maxpos ) { maxpos=$2 }
  #}

  if ( PERSITE && LOCUS != "" ) { $1=LOCUS"_"$1 }

	# Process only SNPs (possibly monomorphic or multiallelic)
  # To obtain results identical to ksamuk/pixy, set $5 !~ /\*|,|[ACGT][ACGT]/
  # To process SNPs that only have one ALT allele
	if ( $4 ~ /^[ACGT]$/ && $5 !~ /\*|[ACGT][ACGT]/ ) {
  
    # Increment gene length for estimation of % missing
    L++

		# Reset site-specific parameters
		for (g in groups) { miss[g]=0; misind[g]=0; nalleles[g]=0; nseen[g]=0 }
		delete alleles
    delete seen
    delete seenlist

		# Pool GT values for groups, count each state and missing data
		for (i=10; i<=NF; i++) {
      grp=groupindex[i]
      if ( grp != "" ) {
        gtend=match( $i, ":" )
        if (gtend==0) { gtend = length($i) + 1 }
		  	for (c=1; c<match( $i, ":" ); c+=2) {
          al=substr($i,c,1)
		  		if ( al == "." ) {
		  			miss[grp]+=match( $i, ":" )/2
            misind[grp]++
            break
          } else {
            if ( HET ) { thisal[al]++ }
		  			alleles[grp,al]++
		  			nalleles[grp]++
            if ( !seen[grp,al] ) {
              seen[grp,al]++
              seenlist[grp]=al seenlist[grp]
              nseen[grp]++
            }
          }
		  	}
      }
      if ( HET && nalleles[grp] ) {
        Lal[grp]++
        if ( MULT || nseen[grp]<=2 ) {
          if ( PIXY || PERSITE ) { 
            for ( x in thisal ) { numerator[grp]+=thisal[x]*(nalleles[grp]-thisal[x]) }
            denominator[grp]+=nalleles[grp]*(nalleles[grp]-1)
          } else {
              for ( x in thisal ) { pi[grp]+=(thisal[x]*(nalleles[grp]-thisal[x])) / (nalleles[grp]*(nalleles[grp]-1)) }
          }
        }
        if ( PERSITE ) { print $1"_"$2, 1, g, ".", 1, "het", formatOutput( numerator[grp], denominator[grp] ) }
        delete thisal
      }
		}

		# Calculate pi for groups with <50% missing data 
    # (if PIXY, use all sites with at least one genotype since miss[g]==0 )
    if ( !HET ) {
  		for ( g in seenlist ) {
  			if ( miss[g]/(nalleles[g]+miss[g]) <= MIS && ( MULT || nseen[g]<=2 ) ) {
  
  				# Increment number of sites used for calculation
  				Lal[g]++
          
          # Extract allele counts of the group
          delete thesealleles
          delete bothalleles
          split(seenlist[g], xx, "")
          for (al in xx) {
            bothalleles[xx[al]]++
            thesealleles[xx[al]] = alleles[g,xx[al]]
          }
  
  				# Add to pi: probability that two randomly picked alleles differ
          # New formula below from https://pubmed.ncbi.nlm.nih.gov/36031871/
          thisnum[g]=nalleles[g]^2
          thisden[g]=nalleles[g]*(nalleles[g]-1)
          for ( x in thesealleles ) { thisnum[g]-=thesealleles[x]^2 }
          #
          # Possible improvement: check if ploidy is mixed once per group
          if ( TAJLIKE && nseen[g]==2 ) {
            if ( !targetN[g] ) { targetN[g]=int( (nalleles[g]+miss[g]) * (1-MIS) ) }
            maf=nalleles[g]
            for ( x in thesealleles ) { if ( thesealleles[x] < maf ) { maf=thesealleles[x] } }
            segr[g]+=( rand() >= probLoseSegr( maf, targetN[g], nalleles[g] ) )
            # Calculate folded SFS
            #sfs[g,maf]++
            #if ( maf > maxmaf[g] ) { maxmaf[g]=maf }
            #segr[g]+=recalcSegr( maf/nalleles[g], 1, nalleles[g], nalleles[g]+miss[g] )
          }

          if ( PERSITE ) { 
            if ( thisden[g] ) { print $1"_"$2, 1, g, ".", 1, "pi", formatOutput( thisnum[g], thisden[g] ) }
          } else {
              if ( PIXY ) { numerator[g]+=thisnum[g]; denominator[g]+=thisden[g] 
              } else { pi[g]+=thisnum[g]/thisden[g] }
            }
  
  				# Calculate pi between this group and all other groups with <50% missing data
          if ( DXY ) {
  			  	for ( g2 in seenlist ) {
  			  		if ( g2 < g && miss[g2]/(nalleles[g2]+miss[g2]) <= MIS && ( MULT || nseen[g2]<=2 ) ) {
              
                # Is the union of allelic states from g1 and g2 bigger than nseen[g1]?
                poolsize=nseen[g]

                # Extract alleles of the group
                delete thosealleles
                split(seenlist[g2], yy, "")
                for (al in yy) {
                  bothalleles[yy[al]]++ # so far keeps alleles from comparisons of g with previous groups
                  thosealleles[yy[al]] = alleles[g2,yy[al]]
                  if ( !thesealleles[yy[al]] ) { poolsize++ }
                }

                # If not MULT, proceed only if common allele pool has <=2 alleles
                if ( MULT || poolsize <= 2 ) {

  			  	    	# Increment number of sites used for dxy
  			  	    	Lal[g,g2]++
                  
  			  	    	# Add to dxy: probability that two alleles picked from two groups differ
                  # subtraction rather than addition inspired by https://pubmed.ncbi.nlm.nih.gov/36031871/
                  thisnum[g,g2]=nalleles[g]*nalleles[g2]
                  thisden[g,g2]=thisnum[g,g2]
                  if ( FST ) { thisfstnum=""; thisfstden="" }
                  for ( x in bothalleles ) { 
                    if ( thesealleles[x] || thosealleles[x] ) {
                      thisnum[g,g2]-=thesealleles[x]*thosealleles[x]
                      if ( FST ) {
                        if ( FST=="HUD" ) { 
                          incrementFstHudson( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                        } else if ( FST=="WC" ) { 
                          incrementFstWeirCockerham( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                        } else if ( FST=="WC_ORIG" ) { 
                          incrementFstWeirCockerhamOrig( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                        } 
                        if ( !MULT ) { break } # no need to increment twice for biallelic comparisons
                      }
                    }
                  }
                  if ( PERSITE ) { 
                    if ( thisden[g,g2] ) { print $1"_"$2, 1, g, g2, 1, "dxy", formatOutput( thisnum[g,g2], thisden[g,g2] ) }
                    if ( FST && thisfstden ) { print $1"_"$2, 1, g, g2, 1, "Fst_"FST, formatOutput( thisfstnum, thisfstden ) }
                  } else {
                      if ( PIXY ) { numerator[g,g2]+=thisnum[g,g2]; denominator[g,g2]+=thisden[g,g2] 
                      } else { dxy[g,g2]+=thisnum[g,g2]/thisden[g,g2] }
                      if ( FST ) { fst_numerator[g,g2]+=thisfstnum; fst_denominator[g,g2]+=thisfstden }
                    }
  			  	    }
              }
  			    }
  		    }
        }
	    }
    }
  }
}

END {
  if ( !PERSITE ) {
    
    # Prepare "metric" field for output
    if ( PIXY ) { 
      pimetric="pi_pixy"
      dxymetric="dxy_pixy"
    } else { 
      pimetric="pi_w"
      dxymetric="dxy_w"
    }
    if ( HET ) {
      pimetric= "het" substr(pimetric, match(pimetric, "_") )
    }

    if ( LOCUS=="" ) { maxpos=$2; LOCUS=chrom"_"minpos"_"maxpos }

  	for (g in groups) {
      if ( Lal[g] ) {
        if ( PIXY ) { pinum[g] = numerator[g]; piden[g] = denominator[g] 
        } else { pinum[g] = pi[g]; piden[g] = Lal[g] }
        print LOCUS, L, g, ".", Lal[g], pimetric, formatOutput( pinum[g], piden[g] )
        if ( TAJLIKE && segr[g] ) {
          for (i=1;i<targetN[g];i++) { a1[g]+=1/i; a2[g]+=1/i^2 }
          #for (i=1;i<nalleles[g]+miss[g];i++) { tgt_a1[g]+=1/i; tgt_a2[g]+=1/i^2 }

          # Is theta pi from SFS any different?
          #for (i=1;i<maxmaf[g];i++) { tP[g]+=maxmaf[g]/(maxmaf[g]-1)*2*sfs[g,i]*(i/maxmaf[g])*(1-i/maxmaf[g]) }

          # Ferretti-style correction of a1 + my correction of segr[g] with recalcSegr() give the best result
          #a1[g]/=Lal[g]
          #a2[g]/=Lal[g]
          tajnum[g]= pinum[g]/piden[g]*Lal[g] - segr[g]/a1[g]
          tajden[g]=calcTajimaVar( segr[g], a1[g], a2[g], targetN[g] ) # could as well replace by nalleles[g]+miss[g]
          print LOCUS, L, g, ".", Lal[g], "TajD-like", formatOutput( tajnum[g], tajden[g] )
        }
      }
    }
  	for (i in combs) {
      if ( Lal[i] ) { 
        if ( PIXY ) { dxynum[i] = numerator[i]; dxyden[i]=denominator[i] 
        } else { dxynum[i] = dxy[i]; dxyden[i]=Lal[i] }
        split(i, ii, SUBSEP)
        print LOCUS, L, ii[1], ii[2], Lal[i], dxymetric, formatOutput( dxynum[i], dxyden[i] )
        if ( fst_denominator[i] ) { 
          print LOCUS, L, ii[1], ii[2], Lal[i], "Fst_"FST, formatOutput( fst_numerator[i], fst_denominator[i] ) 
        }
      }
    }
  }
}

### FUNCTIONS

# Print just the value or value, numerator, denominator if VERBOSE
function formatOutput( numerator, denominator ) {
  out=numerator/denominator
  if ( VERBOSE ) { 
      out = out"\t"numerator"\t"denominator
  }
  return out
}

function incrementFstHudson( a1, a2, n1, n2 ) {
  pi1 = a1 * (n1 - a1) / (n1*(n1-1))
  pi2 = a2 * (n2 - a2) / (n2*(n2-1))
  hw = pi1 + pi2
  hb = ( a1 * (n2-a2) + a2*(n1-a1) ) / (n1*n2)
  thisfstnum+=hb-hw
  thisfstden+=hb
} 

function incrementFstWeirCockerham( a1, a2, n1, n2 ) {
  # Formula from Bhatia et al. 2013, eq. (6)

  sizes = n1 * n2 / ( n1 + n2 )
  frac = 1 / ( n1 + n2 - 2 )
  mism = n1 * ( a1 / n1 ) * ( 1 - a1 / n1 ) + n2 * ( a2 / n2 ) * ( 1 - a2 / n2 )

  den = sizes * ( a1 / n1 - a2 / n2 )^2 + ( 2 * sizes - 1 ) * frac * mism
  if ( ! den ) { return } # WC Fst is NaN at uniform sites
  thisfstnum += den - 2 * sizes * frac * mism
  thisfstden += den

}

function incrementFstWeirCockerhamOrig( a1, a2, n1, n2 ) {
  # Below is closer to Weir & Cockerham (1984) but something is wrong
  # Pretending r=2 now
  h1 = (a1*(n1-a1)) / (n1*(n1-1)) # maybe optimize later
  h2 = (a2*(n2-a2)) / (n2*(n2-1)) # maybe optimize later
  n1 /= 2 # count of "diploid individuals"
  n2 /= 2
  p1 = a1
  p2 = a2
  n_bar = (n1 + n2) / 2 # average number of "diploid individuals", divided by r
  rn = 2*n_bar
  n_C = rn - (n1^2 + n2^2)/rn # also divided by r-1
  p_bar = ( n1 * p1 + n2 * p2 ) / rn
  s2 = ( n1 * (p1 - p_bar) + n2 * (p2 - p_bar) ) / n_bar # also divided by r-1
  h_bar = ( n1 * h1 + n2 * h2 ) / rn

  a = ( n_bar/n_C ) * ( s2 - ( 1/n_bar-1 ) * ( p_bar * ( 1 - p_bar ) - 0.5 * s2 - 0.25 * h_bar ) ) # 0.5 is (r-1)/r
  b = ( n_bar / ( n_bar - 1 ) ) * ( p_bar * ( 1 - p_bar ) - 0.5 * s2 - ( ( 2 * n_bar-1 ) / ( 4 * n_bar ) ) * h_bar )
  c = 0.5*h_bar

  thisfstnum+=a
  thisfstden+=a+b+c
  }

# Tajima's D-like statistic calculation
# The formula below is classic Tajima's D but with missing data we calculate a1 and a2 in a slightly different way
function calcTajimaVar( S, a1, a2, n ) {
  b1=(n+1)/(3*n-3)
  b2=(2*(n^2+n+3))/(9*n*(n-1))
  c1=b1-1/a1
  c2=b2-(n+2)/(a1*n)+a2/(a1^2)
  e1=c1/a1
  e2=c2/(a1^2+a2)
  return sqrt(e1*S + e2*S*(S-1))
}

function recalcSegr( prob, S, n, target ) {
  while ( n < target ) {
    S+=(prob^n+(1-prob)^n)*S/(n+1)
    n++
  }
  return S
}

function probLoseSegr( count, targetN, nalleles,    excess, prob ) {
  excess = nalleles-targetN
  prob = 0
  prob+=probLoseSegrCalc( count, excess, nalleles )
  prob+=probLoseSegrCalc( nalleles-count, excess, nalleles )
  return prob
}

function probLoseSegrCalc( count, excess, nalleles,    pnum, pden ) {
  if ( excess < count ) { return 0 }
  pnum=1
  for (i=2;i<=count;i++) { pnum*=i } # factorial of allele count
  if ( excess > count ) { for (i=count; i<=excess; i++) { pnum*=(nalleles-i) } }
  pden=1
  for (i=nalleles-excess; i<=nalleles; i++) { pden*=i }
  return pnum/pden
}
