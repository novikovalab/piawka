#!/usr/bin/mawk -f

BEGIN{ 
OFS="\t" 
help=" \
    This script takes a grouping file and a decompressed VCF as input.\n \
    It outputs pi within each group and dxy between each pair of groups.\n \
    \n \
    Usage: \n \
    piawka [OPTIONS] groups_file <( zcat file.vcf.gz ) \n \
      or in pipeline like \n \
    zcat file.vcf.gz | piawka [OPTIONS] groups_file -   # the last dash is important here! \n \
    \n \
    Options: \n \
    PIXY=1       calculate pixy-like pi instead of average weighted pi (default)\n \
    DXY=1        count between-group Dxy in addition to within-group pi (default)\n \
    MULT=1       use multiallelic sites\n \
    PERSITE=1    output values for each site instead of summary values\n \
    LOCUS='text' custom name of region to be shown in first column\n \
    HET=1        output heterozygosity, i.e. within-sample pi (unsets default DXY=1)\n \
    FST=XXX or 1 output Fst using one of the following estimators (sets DXY=1):\n \
                 HUD (default) : Hudson (1992) after Bhatia et al. (2013, eq. 10)\n \
                 WC : Weir and Cockerham (1984), biased for unequal groups with dissimilar Fst \n \
    MIS=0.5      maximum share of missing genotypes in groups at site (between 0 and 1);\n \
                 default 1 with PIXY=1 and 0.5 with PIXY=0\n \
    VERBOSE=1    output numerator, denominator, nGenotypes and nMissing as 8th-11th columns\n \
                 with PIXY=0 and PERSITE=0, numerator = sum of values and denominator = nUsed\n \
    NSITES=1000  length of locus to be passed as nSites (e.g. gene length);\n \
                 default is the range of the POS field in the provided VCF\n \
    TAJLIKE=1    output Tajima's D-like statistic (different variance; unset by PERSITE=1 or MULT=1)\n \
                 not to be run on mixed-ploidy groups!\n \
    RHO=1        calculate Ronfort's (1998) rho -- a divergence metric most suitable for\n \
                 different-ploidy pops comparisons; not to be run on mixed-ploidy groups!\n \
    \n \
    Example groups.tsv:\n \
    \n \
    sample1 grp1\n \
    sample2 grp1\n \
    sample3 grp2\n \
    sample4 grp3\n \
    \n \
    Samples missing from the VCF or groups file will be silently skipped.\n \
    If one sample is assigned to two groups, only one will be used.\n \
    \n \
    Output is the long-format table with seven columns (no header):\n \
    \n \
    locus_name, nSites, pop1, pop2, nUsed, metric, value\n \
    \n \
    where nSites = SNPs + invariant sites,\n \
          nUsed = nSites - sites with too many alleles or too much missing data\n \
    \n \
    Version: 0.7.10"
assert( ARGC>=2, "two mandatory arguments are the groups file and the VCF file" )
}

# Process VCF lines ( rules for the groups file and header are below )
DATALINES {

  # Increment nSites
  if ( NSITES=="" || LOCUS=="" ) {
    if ( !minpos[$1] ) { minpos[$1]=$2 }
    maxpos[$1]=$2
  }

	# Process only SNPs (possibly monomorphic or multiallelic)
  # To obtain results identical to ksamuk/pixy, set $5 !~ /\*|,|[ACGT][ACGT]/
  # To process SNPs that only have one ALT allele
	if ( $4 ~ /^[ACGT]$/ && $5 !~ /\*|[ACGT][ACGT]/ ) {
  
    if ( PERSITE && LOCUS != "" ) { $1=LOCUS"_"$1 }
  
		# Reset site-specific parameters
		for (g in groups) { miss[g]=0; misind[g]=0; nalleles[g]=0; nseen[g]=0 }
		delete alleles
    delete seen
    delete seenlist

		# Pool GT values for groups, count each state and missing data
		for (i in groupindex) {
      grp=groupindex[i]
      gtend=match( $i, ":" )
      if ( gtend==0 ) { gtend=length($i)+1 }
	  	for (c=1; c<gtend; c+=2) {
        al=substr($i,c,1)
	  		if ( al == "." ) {
	  			miss[grp]+=gtend/2
          break
        } else {
          if ( HET ) { thisal[al]++ }
	  			alleles[grp,al]++
	  			nalleles[grp]++
          if ( !seen[grp,al] ) {
            seen[grp,al]++
            seenlist[grp]=al seenlist[grp]
            nseen[grp]++
          }
        }
	  	}
      if ( HET && nalleles[grp] ) {
        nUsed[grp]++
        if ( MULT || nseen[grp]<=2 ) {
          if ( PIXY || PERSITE ) { 
            for ( x in thisal ) { numerator[grp]+=thisal[x]*(nalleles[grp]-thisal[x]) }
            denominator[grp]+=nalleles[grp]*(nalleles[grp]-1)
          } else {
              for ( x in thisal ) { pi[grp]+=(thisal[x]*(nalleles[grp]-thisal[x])) / (nalleles[grp]*(nalleles[grp]-1)) }
          }
        }
        if ( PERSITE ) { print $1"_"$2, 1, g, ".", 1, "het", formatOutput( numerator[grp], denominator[grp], nalleles[grp], miss[g] ) }
        delete thisal
      }
		}

		# Calculate pi for groups with <50% missing data 
    # (if PIXY, use all sites with at least one genotype since miss[g]==0 )
    if ( !HET ) {
  		for ( g in seenlist ) {
  			if ( miss[g]/(miss[g]+nalleles[g]) <= MIS && ( MULT || nseen[g]<=2 ) ) {
  
  				# Increment number of sites used for calculation
  				nUsed[g]++
          
          # Extract allele counts of the group
          delete thesealleles
          delete bothalleles
          split(seenlist[g], xx, "")
          for (al in xx) {
            bothalleles[xx[al]]++
            thesealleles[xx[al]] = alleles[g,xx[al]]
          }
  
  				# Add to pi: probability that two randomly picked alleles differ
          # New formula below from https://pubmed.ncbi.nlm.nih.gov/36031871/
          thisnum[g]=nalleles[g]^2
          thisden[g]=nalleles[g]*(nalleles[g]-1)
          for ( x in thesealleles ) { thisnum[g]-=thesealleles[x]^2 }
          #
          # Possible improvement: check if ploidy is mixed once per group
          if ( TAJLIKE && nseen[g]==2 ) {
            for (i=1;i<nalleles[g];i++) { a1[g]+=1/i; a2[g]+=1/i^2 }
            segr[g]+=recalcS_expected( 1, nalleles[g], nalleles[g]+miss[g] )
            truesegr[g]++
          }

          if ( PERSITE ) { 
            if ( thisden[g] ) { print $1"_"$2, 1, g, ".", 1, "pi", formatOutput( thisnum[g], thisden[g], nalleles[g], miss[g] ) }
          } else {
              if ( PIXY ) { 
                numerator[g]+=thisnum[g]; denominator[g]+=thisden[g] 
              } else { 
                pi[g]+=thisnum[g]/thisden[g]
              }
              if ( VERBOSE ) {
                allmiss[g]+=miss[g]
                allgeno[g]+=nalleles[g]
              }
            }
  
  				# Calculate pi between this group and all other groups with <50% missing data
          if ( DXY ) {
  			  	for ( g2 in seenlist ) {
  			  		if ( g2 < g && miss[g2]/(miss[g2]+nalleles[g2]) <= MIS && ( MULT || nseen[g2]<=2 ) ) {
              
                # Is the union of allelic states from g1 and g2 bigger than nseen[g1]?
                poolsize=nseen[g]

                # Extract alleles of the group
                delete thosealleles
                split(seenlist[g2], yy, "")
                for (al in yy) {
                  bothalleles[yy[al]]++ # so far keeps alleles from comparisons of g with previous groups
                  thosealleles[yy[al]] = alleles[g2,yy[al]]
                  if ( !thesealleles[yy[al]] ) { poolsize++ }
                }

                # If not MULT, proceed only if common allele pool has <=2 alleles
                if ( MULT || poolsize <= 2 ) {

  			  	    	# Increment number of sites used for dxy
  			  	    	nUsed[g,g2]++
                  
  			  	    	# Add to dxy: probability that two alleles picked from two groups differ
                  # subtraction rather than addition inspired by https://pubmed.ncbi.nlm.nih.gov/36031871/
                  thisnum[g,g2]=nalleles[g]*nalleles[g2]
                  thisden[g,g2]=thisnum[g,g2]
                  if ( FST ) { thisfstnum=""; thisfstden="" }
                  for ( x in bothalleles ) { 
                    if ( thesealleles[x] || thosealleles[x] ) {
                      thisnum[g,g2]-=thesealleles[x]*thosealleles[x]
                      if ( FST ) {
                        if ( FST=="HUD" ) { 
                          incrementFstHudson( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                        } else if ( FST=="WC" ) { 
                          incrementFstWeirCockerham( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                        } 
                        if ( !MULT ) { break } # no need to increment twice for biallelic comparisons
                      }
                    }
                  }
                  if ( RHO ) {
                    if (!thisden[g2]) {
                      thisnum[g2]=nalleles[g2]^2
                      thisden[g2]=nalleles[g2]*(nalleles[g2]-1)
                      for ( x in thosealleles ) { thisnum[g2]-=thesealleles[x2]^2 }
                    }
                    # Here Hs = average of pi values of two populations,
                    #      Ht = pi of two populations pooled,
                    #      Hsp = Hs corrected for ploidy
                    thisHtnum=(nalleles[g] + nalleles[g2])^2
                    thisHtden=(nalleles[g] + nalleles[g2]) * (nalleles[g] + nalleles[g2] - 1)
                    for ( x in bothalleles ) { thisHtnum-=(thesealleles[x]+thosealleles[x])^2 }
                    thisHsnum = ( (thisnum[g]*thisden[g2] ) + (thisnum[g2]*thisden[g]) )
                    thisHsden = 2 * thisden[g] * thisden[g2] # same as Hspden
                    thisHspnum = ( (thisnum[g]*thisden[g2]*(ploidy[g]-1)/ploidy[g] ) + (thisnum[g2]*thisden[g]*(ploidy[g2]-1)/ploidy[g2]) )
                  }
                  if ( PERSITE ) { 
                    if ( thisden[g,g2] ) { print $1"_"$2, 1, g, g2, 1, "dxy", formatOutput( thisnum[g,g2], thisden[g,g2], nalleles[g]+nalleles[g2], miss[g]+miss[g2] ) }
                    if ( FST && thisfstden ) { print $1"_"$2, 1, g, g2, 1, "Fst_"FST, formatOutput( thisfstnum, thisfstden, nalleles[g]+nalleles[g2], miss[g]+miss[g2] ) }
                    if ( RHO ) { 
                      Hs = thisHsnum/thisHsden
                      Ht = thisHtnum/thisHtden
                      Hsp = thisHspnum/thisHsden
                      Hpt = Hs + 2 * (Ht - Hs)
                      thisrhonum=Hpt-Hs
                      thisrhoden=Hpt-Hsp
                      print $1"_"$2, 1, g, g2, 1, "Rho", formatOutput( thisrhonum, thisrhoden, nalleles[g]+nalleles[g2], miss[g]+miss[g2] ) 
                    }
                  } else {
                      if ( PIXY ) { numerator[g,g2]+=thisnum[g,g2]; denominator[g,g2]+=thisden[g,g2] 
                      } else { dxy[g,g2]+=thisnum[g,g2]/thisden[g,g2] }
                      if ( FST ) { fst_numerator[g,g2]+=thisfstnum; fst_denominator[g,g2]+=thisfstden }
                      if ( RHO ) {
                        Htnum[g,g2] += thisHtnum 
                        Htden[g,g2] += thisHtden 
                        Hsnum[g,g2] += thisHsnum
                        Hsden[g,g2] += thisHsden 
                        Hspnum[g,g2] += thisHspnum
                      }
                  }
  			  	    }
              }
  			    }
  		    }
        }
	    }
    }
  }
  next
}

# Groups file (first in command line): store lists of group members in `groups` array
NR==FNR { 
  if (FNR==1) { assert(NF==2, "the argument before the last must be a 2-column groups file") }
  groupmem[$1]=HET ? $1 : $2
  next
}

# Second file (VCF), header line: assign samples to groups
NR>FNR && /^#CHROM/ {

  # Set default variable values
  if ( PIXY == "" ) { PIXY=1 }
  if ( !HET && DXY == "" ) { DXY=1 }
  if ( FST ) { DXY=1; if ( FST==1 ) { FST = "HUD" } }
  if ( MIS == "" ) { PIXY ? MIS=1 : MIS=0.5 }
  if ( NSITES!="" ) { nSites=NSITES }
  if ( MULT ) { RHO=0 }

  # Assign sample positions to groups
  for (i=10; i<=NF; i++) {
    if ( groupmem[$i] != "" ) { 
       groupindex[i]=groupmem[$i]
       groups[groupmem[$i]]++
     }
  }
  # Store group combinations
  if ( DXY && !PERSITE ) {
    for (g in groups) {
      for (g2 in groups) {
        if (g2 < g) { combs[g,g2]++ }
      }
    }
  }
  DATALINES=NR
  # Assign ploidy to groups using variant calls from next line, detect mixed-ploidy groups
  if ( TAJLIKE || RHO ) {
    getline nextline
    split(nextline, fields, FS)
    # Count alleles for each group, then divide by number of samples
    for (i in groupindex) {
      ploidy[groupindex[i]] += ( match(fields[i], ":")>0 ? match(fields[i], ":") : length(fields[i])+1 )
    }
    for (g in groups) {
      ploidy[g] /= 2*groups[g]
    }
    if ( ploidy[g] % 1 != 0 && ( TAJLIKE || RHO ) ) {
      print "Warning: mixed ploidy population "g" will give unreliable results with " TAJLIKE ? "TAJLIKE" : "RHO" > "/dev/stderr"
    }
  }
  next
}

END {
  if (_assert_exit) { exit 1 }
  assert( DATALINES, "no VCF header provided")
  if (NR==DATALINES) { print "Warning: no data read for locus "LOCUS > "/dev/stderr" }
  if ( !PERSITE ) {
    
    # Prepare "metric" field for output
    PIXY ? metric="pixy" : metric="w"
    if ( HET ) { metric="het_" metric }

    if ( LOCUS=="" ) {
      for ( i in minpos ) { 
          LOCUS = i"_"minpos[i]"_"maxpos[i]"_"LOCUS
      }
      LOCUS=substr(LOCUS,1,length(LOCUS)-1)
    }
    if ( NSITES=="" ) { 
      for ( i in minpos ) {
        nSites+=maxpos[i]-minpos[i]+1
      }
    }

  	for (g in groups) {
      if ( nUsed[g] ) {
        if ( PIXY ) { pinum[g] = numerator[g]; piden[g] = denominator[g] 
        } else { pinum[g] = pi[g]; piden[g] = nUsed[g] }
        print LOCUS, nSites, g, ".", nUsed[g], HET ? metric : "pi_"metric, formatOutput( pinum[g], piden[g], allgeno[g], allmiss[g] )
        if ( TAJLIKE && segr[g] ) {
          tP[g]=pinum[g]/piden[g]*nUsed[g]
          a1[g]/=truesegr[g]
          a2[g]/=truesegr[g]
          tajnum[g]= tP[g] - segr[g]/a1[g]
          tajden[g]=calcTajimaVar( segr[g], a1[g], a2[g], nalleles[g]+miss[g] ) # could as well replace by nalleles[g]+miss[g]
          print LOCUS, L, g, ".", nUsed[g], "TajD-like", formatOutput( tajnum[g], tajden[g] )
        }
      }
    }
  	for (i in combs) {
      if ( nUsed[i] ) { 
        if ( PIXY ) { dxynum[i] = numerator[i]; dxyden[i]=denominator[i] 
        } else { dxynum[i] = dxy[i]; dxyden[i]=nUsed[i] }
        split(i, ii, SUBSEP)
        print LOCUS, nSites, ii[1], ii[2], nUsed[i], "dxy_"metric, formatOutput( dxynum[i], dxyden[i], allgeno[ii[1]]+allgeno[ii[2]], allmiss[ii[1]]+allmiss[ii[2]] )
        if ( fst_denominator[i] ) { 
          print LOCUS, nSites, ii[1], ii[2], nUsed[i], "Fst_"FST, formatOutput( fst_numerator[i], fst_denominator[i], allgeno[ii[1]]+allgeno[ii[2]], allmiss[ii[1]]+allmiss[ii[2]] ) 
        }
        if ( RHO && Hsden[i] && Htden[i] ) { 
          Hs = Hsnum[i]/Hsden[i]
          Ht = Htnum[i]/Htden[i]
          Hsp = Hspnum[i]/Hsden[i]
          Hpt = Hs + 2 * (Ht - Hs)
          rho_numerator=Hpt-Hs
          rho_denominator=Hpt-Hsp
          print LOCUS, nSites, ii[1], ii[2], nUsed[i], "Rho", formatOutput( rho_numerator, rho_denominator, allgeno[ii[1]]+allgeno[ii[2]], allmiss[ii[1]]+allmiss[ii[2]] ) 
        }
      }
    }
  }
}

### FUNCTIONS

# Print just the value or value, numerator, denominator if VERBOSE
function formatOutput( numerator, denominator, nGeno, nMiss ) {
  out=numerator/denominator
  if ( VERBOSE ) { 
      out = out"\t"numerator"\t"denominator"\t"nGeno"\t"nMiss
  }
  return out
}

function incrementFstHudson( a1, a2, n1, n2 ) {
  pi1 = a1 * (n1 - a1) / (n1*(n1-1))
  pi2 = a2 * (n2 - a2) / (n2*(n2-1))
  hw = pi1 + pi2
  hb = ( a1 * (n2-a2) + a2*(n1-a1) ) / (n1*n2)
  thisfstnum+=hb-hw
  thisfstden+=hb
} 

function incrementFstWeirCockerham( a1, a2, n1, n2 ) {
  # Formula from Bhatia et al. 2013, eq. (6)
  sizes = n1 * n2 / ( n1 + n2 )
  frac = 1 / ( n1 + n2 - 2 )
  mism = n1 * ( a1 / n1 ) * ( 1 - a1 / n1 ) + n2 * ( a2 / n2 ) * ( 1 - a2 / n2 )

  den = sizes * ( a1 / n1 - a2 / n2 )^2 + ( 2 * sizes - 1 ) * frac * mism
  if ( ! den ) { return } # WC Fst is NaN at uniform sites
  thisfstnum += den - 2 * sizes * frac * mism
  thisfstden += den
}

# Tajima's D-like statistic calculation
# The formula below is classic Tajima's D but with missing data we calculate a1 and a2 in a slightly different way
function calcTajimaVar( S, a1, a2, n ) {
  b1=(n+1)/(3*n-3)
  b2=(2*(n^2+n+3))/(9*n*(n-1))
  c1=b1-1/a1
  c2=b2-(n+2)/(a1*n)+a2/(a1^2)
  e1=c1/a1
  e2=c2/(a1^2+a2)
  return sqrt(e1*S + e2*S*(S-1))
}

function recalcS_expected(S, n1, n2,    coef1, coef2 ) {
  for (i=1; i<n1; i++) { coef1+=(1/i+1/(n1-i)) }
  for (i=1; i<n2; i++) { coef2+=(1/i+1/(n2-i)) }
  return S*(coef2/coef1)
}

function assert(condition, explanation) {
  if (! condition) {
    print help; print ""
    printf("Error %s:%d: %s\n",
           FILENAME, FNR, explanation) > "/dev/stderr"
    _assert_exit=1
    exit 1
  }
}
