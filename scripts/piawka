#!/bin/sh
"exec" "gawk" "-d" -f "$0" "--" "$@" && 0 {}

@include "getopt.awk"

BEGIN{ 
  OFS="\t"
  help="piawka v0.8.0\nUsage:\npiawka -g groups_tsv -v vcf_gz [OPTIONS]\nOptions:"
  help_col1_width=20
  parsecmd=""
  exit main()
}

# TODO: play with variable scope?

function add_argument(short, long, is_flag, desc,
                  help_col1) {
  narg++
  args_short[narg] = short
  args_long[narg] = long
  args_isflag[narg] = is_flag
  shortopts = shortopts short (is_flag ? "" : ":")
  longopts = longopts long (is_flag ? "" : ":") ","

  help_col1 = "-"short", --"long (is_flag ? "" : " <arg>")
  help = help "\n" sprintf("%-"help_col1_width"s", help_col1) desc
  # TODO: collect arg values into args[long] elements through awkcmd?
  }

function parse_args() {
  while ((c=getopt::getopt(ARGC,ARGV,shortopts,longopts)) != -1) {
    if (c == "?") { return 1 }
    for (i=1;i<=narg;i++) {
      if (getopt::Optopt == args_short[i] || getopt::Optopt == args_long[i]) {
        args[args_long[i]]=(args_isflag[i] ? 1 : getopt::Optarg)
        break
        }
      }
  }
  return 0
}

function main() {
  add_argument("1", "persite", 1, "output values for each site")
  add_argument("a", "all", 1, "output more cols: numerator, denominator, nGeno, nMiss")
  add_argument("b", "bed", 0, "BED file with regions to be analyzed (optional)")
  add_argument("D", "nodxy", 1, "do not output Dxy")
  add_argument("f", "fst", 1, "output Hudson Fst")
  add_argument("F", "fstwc", 1, "output Weir and Cockerham Fst")
  add_argument("g", "groups", 0, "2-columns sample ID / group ID TSV file")
  add_argument("h", "help", 1, "show this help message")
  add_argument("H", "het", 1, "output only per-sample pi = heterozygosity")
  add_argument("l", "locus", 0, "custom name for the analyzed region")
  add_argument("m", "mult", 1, "use multiallelic sites")
  add_argument("M", "miss", 1, "max share of missing GT per group at site")
  add_argument("n", "nsites", 0, "custom value for nSites field (rarely needed)")
  add_argument("P", "nopixy", 1, "do not use pixy weighting of sites")
  add_argument("r", "rho", 1, "output Ronfort's rho")
  add_argument("t", "tajima", 1, "output Tajima's D")
  add_argument("v", "vcf", 0, "gzipped and tabixed VCF file")
  getopt::Optind = 1 # start with 1st opt
  getopt::Opterr = 1 # print getopt errs
  if ( parse_args() != 0 ) { print help; return 0 }
  if (args["help"]) { print help; return 0 }
  vcf_gz=args["vcf"]
  groups_file=args["groups"]
  PIXY=args["nopixy"]
  DXY=!args["nodxy"]
  MULT=args["mult"]
  PERSITE=args["persite"]
  LOCUS=args["locus"]
  HET=args["het"]
  FST=args["fst"]
  if (args["fstwc"]) { FST="WC" }
  MIS=args["miss"]
  VERBOSE=args["all"]
  NSITES=args["nsites"]
  TAJLIKE=args["tajima"]
  RHO=args["rho"]

  assert( vcf_gz!="", "missing argument: -v <file.vcf.gz>" )
  assert( groups_file!="", "missing argument: -g <groups.tsv>" )
  if (bed_file != "") {
    while ( getline < bed_file > 0) {
      reg = $1":"$2+1"-"$3
      bed[$4 == "" ? reg : $4] = reg
      # spawn children here
      }
    }
  # TODO: use bed as target if asked 

  get_groups()
  get_header()
  process_sites()
  return 0
}

# Groups file (first in command line): store lists of group members in `groups` array
function get_groups() { 
  while ( getline < groups_file > 0 ) {
    if (!checked_groups) { assert(NF==2, "the groups file must contain two columns"); checked_groups=1 }
    groupmem[$1]=HET ? $1 : $2
    # next
  }
  close( groups_file )
}

# VCF header: assign samples to groups
function get_header() {
  cmd="bgzip -dc " vcf_gz
  while ( cmd | getline > 0 ) { 
    header_length++
    if ($0 ~ /^#CHROM/ ) {

      # Set default variable values
      if ( PIXY == "" ) { PIXY=1 }
      if ( !HET && DXY == "" ) { DXY=1 }
      if ( FST ) { DXY=1; if ( FST==1 ) { FST = "HUD" } }
      if ( MIS == "" ) { PIXY ? MIS=1 : MIS=0.5 }
      if ( NSITES!="" ) { nSites=NSITES }
      if ( MULT ) { RHO=0 }
    
      # Assign sample positions to groups
      for (i=10; i<=NF; i++) {
        if ( groupmem[$i] != "" ) { 
           groupindex[i]=groupmem[$i]
           groups[groupmem[$i]]++
         }
      }
      # Store group combinations
      if ( DXY && !PERSITE ) {
        for (g in groups) {
          for (g2 in groups) {
            if (g2 < g) { combs[g,g2]++ }
          }
        }
      }
      # Assign ploidy to groups using variant calls from next line, detect mixed-ploidy groups
      if ( TAJLIKE || RHO ) {
        cmd | getline
        # Count alleles for each group, then divide by number of samples
        for (i in groupindex) {
          ploidy[groupindex[i]] += ( match($i, ":")>0 ? match($i, ":") : length($i)+1 )
        }
        for (g in groups) {
          ploidy[g] /= 2*groups[g]
        }
        if ( ploidy[g] % 1 != 0 && ( TAJLIKE || RHO ) ) {
          print "Warning: mixed ploidy population "g" will give unreliable results with " TAJLIKE ? "TAJLIKE" : "RHO" > "/dev/stderr"
        }
      }
      # Start processing sites if no need to query by regions?
      break
    }
  }
  close(cmd)
}

# Process VCF lines
function process_sites() {
  cmd = ( region=="" ? "bgzip -dc " vcf_gz : "tabix "vcf_gz" "region )
  while ( cmd | getline > 0 ) {
    lines_seen++
    if ( lines_seen > header_length ) {
  
      # Increment nSites
      if ( NSITES=="" || LOCUS=="" ) {
        if ( !minpos[$1] ) { minpos[$1]=$2 }
        maxpos[$1]=$2
      }
  
      # Process only SNPs (possibly monomorphic or multiallelic)
      # To obtain results identical to ksamuk/pixy, set $5 !~ /\*|,|[ACGT][ACGT]/
      # To process SNPs that only have one ALT allele
      if ( $4 ~ /^[ACGT]$/ && $5 !~ /\*|[ACGT][ACGT]/ ) {
      
        if ( PERSITE && LOCUS != "" ) { $1=LOCUS"_"$1 }
      
      	# Reset site-specific parameters
      	for (g in groups) { miss[g]=0; misind[g]=0; nalleles[g]=0; nseen[g]=0 }
      	delete alleles
        delete seen
        delete seenlist
  
      	# Pool GT values for groups, count each state and missing data
      	for (i in groupindex) {
          grp=groupindex[i]
          gtend=match( $i, ":" )
          if ( gtend==0 ) { gtend=length($i)+1 }
        	for (c=1; c<gtend; c+=2) {
            al=substr($i,c,1)
        		if ( al == "." ) {
        			miss[grp]+=gtend/2
              break
            } else {
              if ( HET ) { thisal[al]++ }
        			alleles[grp,al]++
        			nalleles[grp]++
              if ( !seen[grp,al] ) {
                seen[grp,al]++
                seenlist[grp]=al seenlist[grp]
                nseen[grp]++
              }
            }
        	}
          if ( HET && nalleles[grp] ) {
            nUsed[grp]++
            if ( MULT || nseen[grp]<=2 ) {
              if ( PIXY || PERSITE ) { 
                for ( x in thisal ) { numerator[grp]+=thisal[x]*(nalleles[grp]-thisal[x]) }
                denominator[grp]+=nalleles[grp]*(nalleles[grp]-1)
              } else {
                  for ( x in thisal ) { pi[grp]+=(thisal[x]*(nalleles[grp]-thisal[x])) / (nalleles[grp]*(nalleles[grp]-1)) }
              }
            }
            if ( PERSITE ) { print $1"_"$2, 1, g, ".", 1, "het", formatOutput( numerator[grp], denominator[grp], nalleles[grp], miss[g] ) }
            delete thisal
          }
      	}
  
      	# Calculate pi for groups with <50% missing data 
        # (if PIXY, use all sites with at least one genotype since miss[g]==0 )
        if ( !HET ) {
      		for ( g in seenlist ) {
      			if ( miss[g]/(miss[g]+nalleles[g]) <= MIS && ( MULT || nseen[g]<=2 ) ) {
      
      				# Increment number of sites used for calculation
      				nUsed[g]++
              
              # Extract allele counts of the group
              delete thesealleles
              delete bothalleles
              split(seenlist[g], xx, "")
              for (al in xx) {
                bothalleles[xx[al]]++
                thesealleles[xx[al]] = alleles[g,xx[al]]
              }
      
      				# Add to pi: probability that two randomly picked alleles differ
              # New formula below from https://pubmed.ncbi.nlm.nih.gov/36031871/
              thisnum[g]=nalleles[g]^2
              thisden[g]=nalleles[g]*(nalleles[g]-1)
              for ( x in thesealleles ) { thisnum[g]-=thesealleles[x]^2 }
              #
              # Possible improvement: check if ploidy is mixed once per group
              if ( TAJLIKE && nseen[g]==2 ) {
                for (i=1;i<nalleles[g];i++) { a1[g]+=1/i; a2[g]+=1/i^2 }
                segr[g]+=recalcS_expected( 1, nalleles[g], nalleles[g]+miss[g] )
                truesegr[g]++
              }
  
              if ( PERSITE ) { 
                if ( thisden[g] ) { print $1"_"$2, 1, g, ".", 1, "pi", formatOutput( thisnum[g], thisden[g], nalleles[g], miss[g] ) }
              } else {
                  if ( PIXY ) { 
                    numerator[g]+=thisnum[g]; denominator[g]+=thisden[g] 
                  } else { 
                    pi[g]+=thisnum[g]/thisden[g]
                  }
                  if ( VERBOSE ) {
                    allmiss[g]+=miss[g]
                    allgeno[g]+=nalleles[g]
                  }
                }
      
      				# Calculate pi between this group and all other groups with <50% missing data
              if ( DXY ) {
      			  	for ( g2 in seenlist ) {
      			  		if ( g2 < g && miss[g2]/(miss[g2]+nalleles[g2]) <= MIS && ( MULT || nseen[g2]<=2 ) ) {
                  
                    # Is the union of allelic states from g1 and g2 bigger than nseen[g1]?
                    poolsize=nseen[g]
  
                    # Extract alleles of the group
                    delete thosealleles
                    split(seenlist[g2], yy, "")
                    for (al in yy) {
                      bothalleles[yy[al]]++ # so far keeps alleles from comparisons of g with previous groups
                      thosealleles[yy[al]] = alleles[g2,yy[al]]
                      if ( !thesealleles[yy[al]] ) { poolsize++ }
                    }
  
                    # If not MULT, proceed only if common allele pool has <=2 alleles
                    if ( MULT || poolsize <= 2 ) {
  
      			  	    	# Increment number of sites used for dxy
      			  	    	nUsed[g,g2]++
                      
      			  	    	# Add to dxy: probability that two alleles picked from two groups differ
                      # subtraction rather than addition inspired by https://pubmed.ncbi.nlm.nih.gov/36031871/
                      thisnum[g,g2]=nalleles[g]*nalleles[g2]
                      thisden[g,g2]=thisnum[g,g2]
                      if ( FST ) { thisfstnum=""; thisfstden="" }
                      for ( x in bothalleles ) { 
                        if ( thesealleles[x] || thosealleles[x] ) {
                          thisnum[g,g2]-=thesealleles[x]*thosealleles[x]
                          if ( FST ) {
                            if ( FST=="HUD" ) { 
                              incrementFstHudson( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                            } else if ( FST=="WC" ) { 
                              incrementFstWeirCockerham( thesealleles[x], thosealleles[x], nalleles[g], nalleles[g2] )
                            } 
                            if ( !MULT ) { break } # no need to increment twice for biallelic comparisons
                          }
                        }
                      }
                      if ( RHO ) {
                        if (!thisden[g2]) {
                          thisnum[g2]=nalleles[g2]^2
                          thisden[g2]=nalleles[g2]*(nalleles[g2]-1)
                          for ( x in thosealleles ) { thisnum[g2]-=thesealleles[x2]^2 }
                        }
                        # Here Hs = average of pi values of two populations,
                        #      Ht = pi of two populations pooled,
                        #      Hsp = Hs corrected for ploidy
                        thisHtnum=(nalleles[g] + nalleles[g2])^2
                        thisHtden=(nalleles[g] + nalleles[g2]) * (nalleles[g] + nalleles[g2] - 1)
                        for ( x in bothalleles ) { thisHtnum-=(thesealleles[x]+thosealleles[x])^2 }
                        thisHsnum = ( (thisnum[g]*thisden[g2] ) + (thisnum[g2]*thisden[g]) )
                        thisHsden = 2 * thisden[g] * thisden[g2] # same as Hspden
                        thisHspnum = ( (thisnum[g]*thisden[g2]*(ploidy[g]-1)/ploidy[g] ) + (thisnum[g2]*thisden[g]*(ploidy[g2]-1)/ploidy[g2]) )
                      }
                      if ( PERSITE ) { 
                        if ( thisden[g,g2] ) { print $1"_"$2, 1, g, g2, 1, "dxy", formatOutput( thisnum[g,g2], thisden[g,g2], nalleles[g]+nalleles[g2], miss[g]+miss[g2] ) }
                        if ( FST && thisfstden ) { print $1"_"$2, 1, g, g2, 1, "Fst_"FST, formatOutput( thisfstnum, thisfstden, nalleles[g]+nalleles[g2], miss[g]+miss[g2] ) }
                        if ( RHO ) { 
                          Hs = thisHsnum/thisHsden
                          Ht = thisHtnum/thisHtden
                          Hsp = thisHspnum/thisHsden
                          Hpt = Hs + 2 * (Ht - Hs)
                          thisrhonum=Hpt-Hs
                          thisrhoden=Hpt-Hsp
                          print $1"_"$2, 1, g, g2, 1, "Rho", formatOutput( thisrhonum, thisrhoden, nalleles[g]+nalleles[g2], miss[g]+miss[g2] ) 
                        }
                      } else {
                          if ( PIXY ) { numerator[g,g2]+=thisnum[g,g2]; denominator[g,g2]+=thisden[g,g2] 
                          } else { dxy[g,g2]+=thisnum[g,g2]/thisden[g,g2] }
                          if ( FST ) { fst_numerator[g,g2]+=thisfstnum; fst_denominator[g,g2]+=thisfstden }
                          if ( RHO ) {
                            Htnum[g,g2] += thisHtnum 
                            Htden[g,g2] += thisHtden 
                            Hsnum[g,g2] += thisHsnum
                            Hsden[g,g2] += thisHsden 
                            Hspnum[g,g2] += thisHspnum
                          }
                      }
      			  	    }
                  }
      			    }
      		    }
            }
          }
        }
      }
      # next
    }
  }
}

END {
  if (_assert_exit) { exit 1 }
  # assert( DATALINES, "no VCF header provided")
  # if (NR==DATALINES) { print "Warning: no data read for locus "LOCUS > "/dev/stderr" }
  if ( !PERSITE ) {
    
    # Prepare "metric" field for output
    PIXY ? metric="pixy" : metric="w"
    if ( HET ) { metric="het_" metric }

    if ( LOCUS=="" ) {
      for ( i in minpos ) { 
          LOCUS = i"_"minpos[i]"_"maxpos[i]"_"LOCUS
      }
      LOCUS=substr(LOCUS,1,length(LOCUS)-1)
    }
    if ( NSITES=="" ) { 
      for ( i in minpos ) {
        nSites+=maxpos[i]-minpos[i]+1
      }
    }

  	for (g in groups) {
      if ( nUsed[g] ) {
        if ( PIXY ) { pinum[g] = numerator[g]; piden[g] = denominator[g] 
        } else { pinum[g] = pi[g]; piden[g] = nUsed[g] }
        print LOCUS, nSites, g, ".", nUsed[g], HET ? metric : "pi_"metric, formatOutput( pinum[g], piden[g], allgeno[g], allmiss[g] )
        if ( TAJLIKE && segr[g] ) {
          tP[g]=pinum[g]/piden[g]*nUsed[g]
          a1[g]/=truesegr[g]
          a2[g]/=truesegr[g]
          tajnum[g]= tP[g] - segr[g]/a1[g]
          tajden[g]=calcTajimaVar( segr[g], a1[g], a2[g], nalleles[g]+miss[g] ) # could as well replace by nalleles[g]+miss[g]
          print LOCUS, L, g, ".", nUsed[g], "TajD-like", formatOutput( tajnum[g], tajden[g] )
        }
      }
    }
  	for (i in combs) {
      if ( nUsed[i] ) { 
        if ( PIXY ) { dxynum[i] = numerator[i]; dxyden[i]=denominator[i] 
        } else { dxynum[i] = dxy[i]; dxyden[i]=nUsed[i] }
        split(i, ii, SUBSEP)
        print LOCUS, nSites, ii[1], ii[2], nUsed[i], "dxy_"metric, formatOutput( dxynum[i], dxyden[i], allgeno[ii[1]]+allgeno[ii[2]], allmiss[ii[1]]+allmiss[ii[2]] )
        if ( fst_denominator[i] ) { 
          print LOCUS, nSites, ii[1], ii[2], nUsed[i], "Fst_"FST, formatOutput( fst_numerator[i], fst_denominator[i], allgeno[ii[1]]+allgeno[ii[2]], allmiss[ii[1]]+allmiss[ii[2]] ) 
        }
        if ( RHO && Hsden[i] && Htden[i] ) { 
          Hs = Hsnum[i]/Hsden[i]
          Ht = Htnum[i]/Htden[i]
          Hsp = Hspnum[i]/Hsden[i]
          Hpt = Hs + 2 * (Ht - Hs)
          rho_numerator=Hpt-Hs
          rho_denominator=Hpt-Hsp
          print LOCUS, nSites, ii[1], ii[2], nUsed[i], "Rho", formatOutput( rho_numerator, rho_denominator, allgeno[ii[1]]+allgeno[ii[2]], allmiss[ii[1]]+allmiss[ii[2]] ) 
        }
      }
    }
  }
}

### FUNCTIONS

# Print just the value or value, numerator, denominator if VERBOSE
function formatOutput( numerator, denominator, nGeno, nMiss ) {
  out=numerator/denominator
  if ( VERBOSE ) { 
      out = out"\t"numerator"\t"denominator"\t"nGeno"\t"nMiss
  }
  return out
}

function incrementFstHudson( a1, a2, n1, n2 ) {
  pi1 = a1 * (n1 - a1) / (n1*(n1-1))
  pi2 = a2 * (n2 - a2) / (n2*(n2-1))
  hw = pi1 + pi2
  hb = ( a1 * (n2-a2) + a2*(n1-a1) ) / (n1*n2)
  thisfstnum+=hb-hw
  thisfstden+=hb
} 

function incrementFstWeirCockerham( a1, a2, n1, n2 ) {
  # Formula from Bhatia et al. 2013, eq. (6)
  sizes = n1 * n2 / ( n1 + n2 )
  frac = 1 / ( n1 + n2 - 2 )
  mism = n1 * ( a1 / n1 ) * ( 1 - a1 / n1 ) + n2 * ( a2 / n2 ) * ( 1 - a2 / n2 )

  den = sizes * ( a1 / n1 - a2 / n2 )^2 + ( 2 * sizes - 1 ) * frac * mism
  if ( ! den ) { return } # WC Fst is NaN at uniform sites
  thisfstnum += den - 2 * sizes * frac * mism
  thisfstden += den
}

# Tajima's D-like statistic calculation
# The formula below is classic Tajima's D but with missing data we calculate a1 and a2 in a slightly different way
function calcTajimaVar( S, a1, a2, n ) {
  b1=(n+1)/(3*n-3)
  b2=(2*(n^2+n+3))/(9*n*(n-1))
  c1=b1-1/a1
  c2=b2-(n+2)/(a1*n)+a2/(a1^2)
  e1=c1/a1
  e2=c2/(a1^2+a2)
  return sqrt(e1*S + e2*S*(S-1))
}

function recalcS_expected(S, n1, n2,    coef1, coef2 ) {
  for (i=1; i<n1; i++) { coef1+=(1/i+1/(n1-i)) }
  for (i=1; i<n2; i++) { coef2+=(1/i+1/(n2-i)) }
  return S*(coef2/coef1)
}

function assert(condition, explanation) {
  if (! condition) {
    print help
    printf("Error %s:%d: %s\n",
           FILENAME, FNR, explanation) > "/dev/stderr"
    _assert_exit=1
    exit 1
  }
}

